# app/web.py
# VERSION FINALE COMPLÃˆTE ET CORRIGÃ‰E â€“ BugPredictor Pro 2025
# Lance avec : streamlit run app/web.py

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

import streamlit as st
import joblib
import pandas as pd
import numpy as np
from pathlib import Path
import tempfile
import subprocess
import os
from lizard import analyze_file  # pip install lizard

# ============================ CONFIGURATION ============================
st.set_page_config(
    page_title="BugPredictor Pro",
    page_icon="bug",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Style magnifique
st.markdown("""
<style>
    .big-font {font-size:58px !important; font-weight:bold; color:#FF2D55; text-align:center; margin-bottom:0;}
    .subtitle {font-size:24px; text-align:center; color:#555; margin-top:0;}
    .risk-high {background:#ffebee; padding:25px; border-radius:15px; border-left:10px solid #f44336; margin:20px 0; text-align:center; font-size:22px;}
    .risk-medium {background:#fff3e0; padding:25px; border-radius:15px; border-left:10px solid #ff9800; margin:20px 0; text-align:center; font-size:22px;}
    .risk-low {background:#e8f5e8; padding:25px; border-radius:15px; border-left:10px solid #4caf50; margin:20px 0; text-align:center; font-size:22px;}
    .stButton>button {width:100%; height:60px; font-size:20px;}
</style>
""", unsafe_allow_html=True)

st.markdown('<p class="big-font">BugPredictor Pro</p>', unsafe_allow_html=True)
st.markdown('<p class="subtitle">PrÃ©diction automatique des fichiers Ã  risque â€¢ Copier-coller â€¢ CSV â€¢ GitHub</p>', unsafe_allow_html=True)

# ============================ CHARGEMENT DU MODÃˆLE ============================
@st.cache_resource
def load_model():
    try:
        # Chemins robustes : fichiers dans le mÃªme dossier que web.py
        base_dir = Path(__file__).parent
        model_path = base_dir / "best_model.pkl"
        scaler_path = base_dir / "scaler.pkl"
        columns_path = base_dir / "feature_columns.pkl"
        
        model = joblib.load(model_path)
        scaler = joblib.load(scaler_path)
        columns = joblib.load(columns_path)
        
        return model, scaler, columns
    except Exception as e:
        st.error(f"ModÃ¨le non trouvÃ© â†’ {e}")
        st.error("VÃ©rifie que best_model.pkl, scaler.pkl et feature_columns.pkl sont dans le dossier 'app/' avec web.py")
        st.stop()

model, scaler, feature_columns = load_model()
st.success("ModÃ¨le XGBoost chargÃ© avec succÃ¨s")

# ============================ FONCTION : CODE COLLÃ‰ (CORRIGÃ‰E & ROBUSTE) ============================
def predict_from_source_code(code: str, language: str = "python"):
    """Analyse du code collÃ© avec lizard et prÃ©dit le risque de bug"""
    if not code.strip():
        return None

    suffix = {"python": ".py", "java": ".java", "javascript": ".js", "c": ".c", "cpp": ".cpp"}.get(language, ".py")
    
    with tempfile.NamedTemporaryFile(mode='w', suffix=suffix, delete=False, encoding='utf-8') as f:
        f.write(code)
        temp_path = f.name

    try:
        analysis = analyze_file(temp_path)
        funcs = analysis.function_list

        # Cas oÃ¹ lizard ne dÃ©tecte aucune fonction (script simple, imports, etc.)
        if not funcs:
            return 0.1  # Faible risque par dÃ©faut

        # Calcul des mÃ©triques moyennes
        data = {
            'nloc': np.mean([f.nloc for f in funcs]) if funcs else 10,
            'cyclomatic_complexity': np.mean([f.cyclomatic_complexity for f in funcs]) if funcs else 1,
            'token_count': np.mean([f.token_count for f in funcs]) if funcs else 50,
            'parameter_count': np.mean([f.parameter_count for f in funcs]) if funcs else 1,
            'loc': analysis.nloc or 10,
            'wmc': len(funcs),
            'lcom3': getattr(analysis, 'average_lcom3', 1.0),
            'rfc': len(funcs) * 4,
            'cbo': 6,
            'dit': 1,
            'noc': 0,
            'dam': 0.5,
        }

        # Construction du vecteur d'entrÃ©e
        vec = np.zeros(len(feature_columns))
        for k, v in data.items():
            if k in feature_columns:
                idx = feature_columns.index(k)
                vec[idx] = v

        # === PRÃ‰DICTION SÃ‰CURISÃ‰E (plus jamais d'erreur d'indice) ===
        vec_2d = vec.reshape(1, -1)                    # Force 2D
        X_scaled = scaler.transform(vec_2d)
        
        if X_scaled.ndim == 1:                         # SÃ©curitÃ© supplÃ©mentaire
            X_scaled = X_scaled.reshape(1, -1)
            
        proba_raw = model.predict_proba(X_scaled)
        
        if proba_raw.ndim == 1:                        # Cas rare mais possible
            proba = float(proba_raw[1])
        else:
            proba = float(proba_raw[0, 1])

        return proba

    except Exception as e:
        st.warning(f"Analyse lizard Ã©chouÃ©e : {e}")
        return 0.2  # Valeur par dÃ©faut raisonnable (risque faible-moyen)
    finally:
        if os.path.exists(temp_path):
            os.unlink(temp_path)

# ============================ FONCTION : GITHUB (VERSION AVEC DIAGNOSTIQUE) ============================
def analyze_github_repo(repo_url: str, branch: str = "main"):
    import os
    
    with tempfile.TemporaryDirectory() as tmpdir:
        # Clone le dÃ©pÃ´t
        cmd = ["git", "clone", "--depth", "1", "--branch", branch, repo_url, tmpdir]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=180)
        
        if result.returncode != 0:
            cmd = ["git", "clone", "--depth", "1", repo_url, tmpdir]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=180)
            
            if result.returncode != 0:
                st.error(f"âŒ Clone Ã©chouÃ©: {result.stderr[:200] if result.stderr else 'Erreur'}")
                return None
        
        # ExÃ©cuter lizard avec une sortie CSV standard
        try:
            cmd = ["lizard", tmpdir, "-l", "python", "--csv"]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode != 0:
                st.warning(f"âš ï¸ Lizard warnings: {result.stderr[:200] if result.stderr else ''}")
            
            output = result.stdout.strip()
            
            if not output:
                st.error("La sortie de lizard est vide")
                return None
            
            # ðŸ”¥ PARSING CRITIQUE : Lizard produit un format CSV spÃ©cifique
            # Format: NLOC,CCN,token,param,function,file,long_name,start,end
            # Mais parfois sans guillemets, avec des virgules dans les champs
            
            lines = output.split('\n')
            if not lines:
                return None
            
            data = []
            for line in lines:
                if not line.strip():
                    continue
                    
                # Split intelligent qui gÃ¨re les virgules dans les champs
                parts = []
                current = ""
                in_quotes = False
                
                for char in line:
                    if char == '"':
                        in_quotes = not in_quotes
                    elif char == ',' and not in_quotes:
                        parts.append(current.strip('"').strip())
                        current = ""
                        continue
                    current += char
                
                parts.append(current.strip('"').strip())
                
                # Nous attendons au moins 6 colonnes
                if len(parts) >= 6:
                    row = {
                        'nloc': float(parts[0]) if parts[0].replace('.', '', 1).isdigit() else 0,
                        'cyclomatic_complexity': float(parts[1]) if parts[1].replace('.', '', 1).isdigit() else 0,
                        'token_count': float(parts[2]) if parts[2].replace('.', '', 1).isdigit() else 0,
                        'parameter_count': float(parts[3]) if parts[3].replace('.', '', 1).isdigit() else 0,
                        'function_name': parts[4] if len(parts) > 4 else '',
                        'file_path': parts[5] if len(parts) > 5 else '',
                        'filename': Path(parts[5] if len(parts) > 5 else '').name  # Extraire juste le nom du fichier
                    }
                    data.append(row)
                else:
                    # Format alternatif ou ligne de somme
                    continue
            
            if not data:
                # Essayer un parsing plus simple
                st.write("Tentative de parsing alternatif...")
                data = []
                for line in lines:
                    parts = line.split(',')
                    if len(parts) >= 6:
                        try:
                            row = {
                                'nloc': float(parts[0]),
                                'cyclomatic_complexity': float(parts[1]),
                                'token_count': float(parts[2]),
                                'parameter_count': float(parts[3]),
                                'function_name': parts[4],
                                'file_path': parts[5],
                                'filename': Path(parts[5]).name
                            }
                            data.append(row)
                        except:
                            continue
            
            if not data:
                st.error("Impossible de parser la sortie de lizard")
                return None
            
            df = pd.DataFrame(data)
            st.write(f"âœ… {len(df)} fonctions analysÃ©es dans {df['filename'].nunique()} fichiers")
            return df
            
        except Exception as e:
            st.error(f"âŒ Erreur lizard: {str(e)}")
            return None

# ============================ SIDEBAR ============================
st.sidebar.image("https://img.icons8.com/fluency/120/bug.png", width=120)
st.sidebar.markdown("## Mode de test")
mode = st.sidebar.radio(
    "Comment veux-tu tester ?",
    ["Copier-coller du code", "MÃ©triques manuelles", "Uploader un CSV", "Repo GitHub/GitLab"]
)

# ===================================================================
# 1. COPIER-COLLER DU CODE
# ===================================================================
if mode == "Copier-coller du code":
    st.markdown("### Colle ton code source ici (Python, Java, JS, C/C++)")
    language = st.selectbox("Langage", ["python", "java", "javascript", "cpp", "c"])
    code = st.text_area("Code Ã  analyser", height=500, placeholder="def hello(name):\n    print(f'Hello {name}')\n    return name.upper()")

    if st.button("Analyser ce code", type="primary", use_container_width=True):
        if code.strip():
            with st.spinner("Analyse du code..."):
                proba = predict_from_source_code(code, language)
                if proba is not None:
                    st.metric("ProbabilitÃ© de bug", f"{proba:.1%}", delta=f"{proba-0.5:+.1%}")

                    if proba >= 0.6:
                        st.markdown(f'<div class="risk-high">RISQUE Ã‰LEVÃ‰ â†’ {proba:.1%} de bug</div>', unsafe_allow_html=True)
                        st.error("Ce fichier est trÃ¨s probablement buggÃ© !")
                    elif proba >= 0.3:
                        st.markdown(f'<div class="risk-medium">RISQUE MOYEN â†’ {proba:.1%}</div>', unsafe_allow_html=True)
                        st.warning("Ã€ surveiller de prÃ¨s")
                    else:
                        st.markdown(f'<div class="risk-low">RISQUE FAIBLE â†’ {proba:.1%}</div>', unsafe_allow_html=True)
                        st.success("Code trÃ¨s probablement sain")
        else:
            st.info("Colle du code pour commencer")

# ===================================================================
# 2. MÃ‰TRIQUES MANUELLES
# ===================================================================
elif mode == "MÃ©triques manuelles":
    st.markdown("### Saisie manuelle des mÃ©triques principales")
    with st.form("manual_form"):
        col1, col2 = st.columns(2)
        with col1:
            loc = st.number_input("LOC", value=100)
            cc = st.number_input("ComplexitÃ© cyclomatique", value=10)
            rfc = st.number_input("RFC", value=30)
            cbo = st.number_input("CBO", value=8)
        with col2:
            wmc = st.number_input("WMC", value=15)
            lcom3 = st.slider("LCOM3", 0.0, 2.0, 1.0)
            dit = st.number_input("DIT", value=2)
            noc = st.number_input("NOC", value=0)

        if st.form_submit_button("PrÃ©dire", use_container_width=True):
            vec = np.zeros(len(feature_columns))
            mapping = {"loc": loc, "cyclomatic_complexity": cc, "rfc": rfc, "cbo": cbo,
                       "wmc": wmc, "lcom3": lcom3, "dit": dit, "noc": noc}
            for k, v in mapping.items():
                if k in feature_columns:
                    vec[feature_columns.index(k)] = v
            
            vec_2d = vec.reshape(1, -1)
            proba = float(model.predict_proba(scaler.transform(vec_2d))[0, 1])
            
            st.metric("Risque", f"{proba:.1%}")
            if proba >= 0.6:
                st.markdown(f'<div class="risk-high">RISQUE Ã‰LEVÃ‰ â†’ {proba:.1%}</div>', unsafe_allow_html=True)
            elif proba >= 0.3:
                st.markdown(f'<div class="risk-medium">RISQUE MOYEN â†’ {proba:.1%}</div>', unsafe_allow_html=True)
            else:
                st.markdown(f'<div class="risk-low">RISQUE FAIBLE â†’ {proba:.1%}</div>', unsafe_allow_html=True)

# ===================================================================
# 3. UPLOAD CSV
# ===================================================================
# ===================================================================
# 3. UPLOAD CSV (VERSION CORRIGÃ‰E)
# ===================================================================
elif mode == "Uploader un CSV":
    st.markdown("### ðŸ“Š Uploader un fichier CSV avec mÃ©triques")
    uploaded = st.file_uploader("CSV avec mÃ©triques (mÃªme colonnes que l'entraÃ®nement)", type=["csv"])
    
    if uploaded:
        try:
            # Charger le CSV
            df = pd.read_csv(uploaded)
            st.success(f"âœ… CSV chargÃ© : {len(df)} lignes, {len(df.columns)} colonnes")
            
            # VÃ©rifier les colonnes
            st.write(f"ðŸ“‹ Colonnes du CSV : {list(df.columns)}")
            st.write(f"ðŸŽ¯ Colonnes attendues par le modÃ¨le : {len(feature_columns)} features")
            
            # Ajouter les colonnes manquantes
            for col in feature_columns:
                if col not in df.columns:
                    df[col] = 0.0
                    st.warning(f"âš ï¸ Colonne '{col}' manquante, remplie avec 0.0")
            
            # SÃ©lectionner uniquement les colonnes requises
            df = df[feature_columns]
            
            # S'assurer que toutes les valeurs sont numÃ©riques
            df = df.apply(pd.to_numeric, errors='coerce').fillna(0.0)
            
            # AperÃ§u des donnÃ©es
            st.markdown("#### ðŸ“ AperÃ§u des donnÃ©es prÃ©parÃ©es")
            st.dataframe(df.head(), use_container_width=True)
            
            # PrÃ©diction SÃ‰CURISÃ‰E
            X_scaled = scaler.transform(df.values)
            
            st.write(f"ðŸ” Forme des donnÃ©es : {X_scaled.shape}")
            
            # PrÃ©diction avec vÃ©rification
            predictions = model.predict_proba(X_scaled)
            st.write(f"ðŸ“Š Forme des prÃ©dictions : {predictions.shape}")
            
            # Extraction SÃ‰CURISÃ‰E des probabilitÃ©s
            if predictions.ndim == 2 and predictions.shape[1] >= 2:
                probas = predictions[:, 1]  # ProbabilitÃ© de la classe 1 (bug)
            elif predictions.ndim == 1:
                probas = predictions  # DÃ©jÃ  les probabilitÃ©s de la classe 1
            else:
                st.error(f"Format de prÃ©diction inattendu : {predictions.shape}")
                probas = np.zeros(len(df))
            
            # RÃ©sultats
            result = df.copy()
            result['risk_score'] = probas
            result['risk_level'] = pd.cut(
                probas, 
                [0, 0.3, 0.6, 1.0], 
                labels=['ðŸŸ¢ Faible', 'ðŸŸ¡ Moyen', 'ðŸ”´ Ã‰levÃ©']
            )
            
            # Trier par risque
            result = result.sort_values('risk_score', ascending=False)
            
            # Statistiques
            st.success(f"ðŸŽ¯ **Analyse terminÃ©e !** {len(result)} fichiers Ã©valuÃ©s")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                high_risk = (result['risk_level'] == 'ðŸ”´ Ã‰levÃ©').sum()
                st.metric("ðŸ”´ Risque Ã‰levÃ©", high_risk)
            with col2:
                medium_risk = (result['risk_level'] == 'ðŸŸ¡ Moyen').sum()
                st.metric("ðŸŸ¡ Risque Moyen", medium_risk)
            with col3:
                low_risk = (result['risk_level'] == 'ðŸŸ¢ Faible').sum()
                st.metric("ðŸŸ¢ Risque Faible", low_risk)
            
            # Top 20 fichiers risquÃ©s
            st.markdown("#### ðŸ† Top 20 fichiers les plus risquÃ©s")
            
            display_cols = []
            if 'filename' in df.columns or 'file' in df.columns or 'File' in df.columns:
                # Chercher une colonne de nom de fichier
                file_col = None
                for col in ['filename', 'file', 'File', 'file_name', 'path']:
                    if col in result.columns:
                        file_col = col
                        break
                
                if file_col:
                    display_df = result[[file_col, 'risk_score', 'risk_level']].head(20).copy()
                    display_df = display_df.rename(columns={file_col: 'Fichier'})
                else:
                    display_df = result[['risk_score', 'risk_level']].head(20).copy()
                    display_df.insert(0, 'Fichier', [f"Ligne {i+1}" for i in range(20)])
            else:
                display_df = result[['risk_score', 'risk_level']].head(20).copy()
                display_df.insert(0, 'Fichier', [f"Ligne {i+1}" for i in range(20)])
            
            display_df['Rang'] = range(1, len(display_df) + 1)
            display_df = display_df[['Rang', 'Fichier', 'risk_score', 'risk_level']]
            display_df['risk_score'] = display_df['risk_score'].apply(lambda x: f"{x:.1%}")
            
            # Colorisation
            def color_risk(val):
                if 'ðŸ”´' in str(val):
                    return 'color: #d32f2f; font-weight: bold'
                elif 'ðŸŸ¡' in str(val):
                    return 'color: #f57c00'
                elif 'ðŸŸ¢' in str(val):
                    return 'color: #388e3c'
                return ''
            
            st.dataframe(
                display_df.style.applymap(color_risk, subset=['risk_level']),
                use_container_width=True,
                height=500
            )
            
            # TÃ©lÃ©chargement
            st.markdown("#### ðŸ’¾ TÃ©lÃ©chargement des rÃ©sultats")
            
            # PrÃ©parer CSV pour tÃ©lÃ©chargement
            csv_data = result.copy()
            csv_data['risk_score'] = csv_data['risk_score'].apply(lambda x: f"{x:.4f}")
            
            # Bouton de tÃ©lÃ©chargement
            download_button = st.download_button(
                label="ðŸ“¥ TÃ©lÃ©charger toutes les prÃ©dictions (CSV)",
                data=csv_data.to_csv(index=False).encode('utf-8'),
                file_name="predictions_complete.csv",
                mime="text/csv",
                use_container_width=True
            )
            
            # TÃ©lÃ©chargement du top 20 uniquement
            top20_csv = display_df.copy()
            top20_csv['risk_score'] = top20_csv['risk_score'].str.replace('%', '')
            top20_button = st.download_button(
                label="ðŸ“¥ TÃ©lÃ©charger le Top 20 (CSV)",
                data=top20_csv.to_csv(index=False).encode('utf-8'),
                file_name="predictions_top20.csv",
                mime="text/csv",
                use_container_width=True
            )
            
        except Exception as e:
            st.error(f"âŒ Erreur lors du traitement du CSV : {str(e)}")
            import traceback
            st.code(traceback.format_exc())


# ===================================================================
# 4. REPO GITHUB / GITLAB (VERSION SIMPLIFIÃ‰E ET CORRIGÃ‰E)
# ===================================================================
else:
    st.markdown("### ðŸ” Analyse complÃ¨te d'un dÃ©pÃ´t GitHub")
    repo_url = st.text_input("URL du dÃ©pÃ´t", "https://github.com/pallets/flask")
    branch = st.text_input("Branche", "main")
    
    if st.button("ðŸš€ Analyser le dÃ©pÃ´t", type="primary", use_container_width=True):
        with st.spinner("Clonage et analyse en cours (2-3 min)..."):
            df_raw = analyze_github_repo(repo_url, branch)
        
        if df_raw is None or df_raw.empty:
            st.error("Ã‰chec de l'analyse")
            st.stop()
        
        st.success(f"âœ… {len(df_raw)} fonctions analysÃ©es dans {df_raw['filename'].nunique()} fichiers")
        
        # ===== Ã‰TAPE 1: AGRÃ‰GATION PAR FICHIER =====
        aggregation = {
            'nloc': 'sum',
            'cyclomatic_complexity': 'mean',
            'token_count': 'sum',
            'parameter_count': 'mean'
        }
        
        valid_agg = {k: v for k, v in aggregation.items() if k in df_raw.columns}
        
        if not valid_agg:
            st.error("Aucune mÃ©trique valide pour l'agrÃ©gation")
            st.stop()
        
        df_files = df_raw.groupby('filename').agg(valid_agg).reset_index()
        
        # ===== Ã‰TAPE 2: AJOUTER LES FEATURES MANQUANTES =====
        st.write(f"ðŸ“Š Le modÃ¨le attend {len(feature_columns)} features")
        
        X_data = pd.DataFrame(0.0, index=range(len(df_files)), columns=feature_columns)
        
        mapping = {
            'nloc': 'nloc',
            'cyclomatic_complexity': 'cyclomatic_complexity',
            'loc': 'nloc',
            'wmc': 'cyclomatic_complexity',
        }
        
        for model_feature, source_feature in mapping.items():
            if model_feature in X_data.columns and source_feature in df_files.columns:
                X_data[model_feature] = df_files[source_feature]
        
        X_data['cbo'] = 5.0
        X_data['rfc'] = 15.0
        X_data['lcom3'] = 1.0
        X_data['dam'] = 0.5
        X_data['dit'] = 1.0
        X_data['noc'] = 0.0
        
        # ===== Ã‰TAPE 3: PRÃ‰DICTION SÃ‰CURISÃ‰E =====
        try:
            st.write(f"âœ… X_data shape: {X_data.shape}")
            st.write(f"âœ… X_data columns: {list(X_data.columns[:10])}...")
            
            X_data = X_data[feature_columns]
            X_scaled = scaler.transform(X_data)
            
            st.write(f"âœ… X_scaled shape: {X_scaled.shape}")
            
            probas = model.predict_proba(X_scaled)
            st.write(f"âœ… Predictions shape: {probas.shape}")
            
            if probas.ndim == 2 and probas.shape[1] >= 2:
                bug_probas = probas[:, 1]
            elif probas.ndim == 1:
                bug_probas = probas
            else:
                st.error(f"Format de prÃ©diction inattendu: {probas.shape}")
                bug_probas = np.zeros(len(df_files))
        
        except Exception as e:
            st.error(f"âŒ Erreur lors de la prÃ©diction: {str(e)}")
            import traceback
            st.code(traceback.format_exc())
            st.stop()
        
        # ===== Ã‰TAPE 4: PRÃ‰SENTATION DES RÃ‰SULTATS =====
        result = pd.DataFrame({
            'Fichier': df_files['filename'],
            'Risque (%)': bug_probas * 100,
            'Score': bug_probas,
            'LOC': df_files.get('nloc', 0).astype(int),
            'ComplexitÃ©': df_files.get('cyclomatic_complexity', 0).round(2)
        })
        
        result['Rang'] = result['Score'].rank(method='first', ascending=False).astype(int)
        result = result.sort_values('Score', ascending=False).reset_index(drop=True)
        
        def categoriser_risque(score):
            if score >= 0.6:
                return 'ðŸ”´ Ã‰levÃ©'
            elif score >= 0.3:
                return 'ðŸŸ¡ Moyen'
            else:
                return 'ðŸŸ¢ Faible'
        
        result['Niveau'] = result['Score'].apply(categoriser_risque)
        
        # ===== Ã‰TAPE 5: AFFICHAGE =====
        st.success(f"ðŸŽ¯ **Analyse terminÃ©e!** {len(result)} fichiers Ã©valuÃ©s")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            risque_max = result['Score'].max() * 100
            st.metric("Risque max", f"{risque_max:.1f}%")
        with col2:
            risque_moyen = result['Score'].mean() * 100
            st.metric("Risque moyen", f"{risque_moyen:.1f}%")
        with col3:
            fichiers_risque = (result['Score'] >= 0.6).sum()
            st.metric("Fichiers Ã  risque", fichiers_risque)
        with col4:
            fichiers_sains = (result['Score'] < 0.3).sum()
            st.metric("Fichiers sains", fichiers_sains)
        
        # Tableau des 20 plus risquÃ©s
        st.markdown("### ðŸ† Top 20 fichiers les plus risquÃ©s")
        
        top20 = result.head(20).copy()
        display_df = top20[['Rang', 'Fichier', 'Niveau', 'Risque (%)', 'LOC', 'ComplexitÃ©']].copy()
        display_df['Risque (%)'] = display_df['Risque (%)'].apply(lambda x: f"{x:.1f}%")
        
        def color_risk(val):
            if 'ðŸ”´' in str(val):
                return 'color: #d32f2f; font-weight: bold'
            elif 'ðŸŸ¡' in str(val):
                return 'color: #f57c00'
            elif 'ðŸŸ¢' in str(val):
                return 'color: #388e3c'
            return ''
        
        st.dataframe(
            display_df.style.applymap(color_risk, subset=['Niveau'])
                     .format({'ComplexitÃ©': '{:.2f}'}),
            use_container_width=True,
            height=700
        )
        
        # ===== Ã‰TAPE 6: TÃ‰LÃ‰CHARGEMENT =====
        st.markdown("### ðŸ’¾ TÃ©lÃ©chargement des rÃ©sultats")
        
        csv_data = result.copy()
        csv_data['Risque (%)'] = csv_data['Risque (%)'].astype(str).str.replace('%', '')
        csv_string = csv_data.to_csv(index=False, encoding='utf-8')
        
        repo_name = repo_url.split('/')[-1].replace('.git', '')
        st.download_button(
            label="ðŸ“¥ TÃ©lÃ©charger le rapport complet (CSV)",
            data=csv_string.encode('utf-8'),
            file_name=f"bug_risk_{repo_name}_{branch}.csv",
            mime="text/csv",
            use_container_width=True
        )
        
        # RÃ©sumÃ© final
        st.markdown("---")
        st.markdown(f"""
        **ðŸ“ˆ RÃ©sumÃ© de l'analyse:**
        - **DÃ©pÃ´t analysÃ©:** {repo_url}
        - **Branche:** {branch}
        - **Fichiers analysÃ©s:** {len(result)}
        - **Score de risque moyen:** {risque_moyen:.1f}%
        - **Fichiers nÃ©cessitant une review (risque > 60%):** {fichiers_risque}
        - **Fichiers considÃ©rÃ©s sains (risque < 30%):** {fichiers_sains}
        """)
# ============================ FOOTER ============================
st.markdown("---")
st.markdown("**Projet GÃ©nie Logiciel â€“ Master S3 â€“ 2025**")
st.markdown("PrÃ©diction de dÃ©fauts avec XGBoost â€¢ lizard â€¢ Streamlit â€¢ Analyse GitHub en temps rÃ©el")